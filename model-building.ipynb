Model building, Evaluation & Evaluaton
Working on Cleaned dataset

# Import necessary libraries
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
# import the cleaned dataset
# Load the dataset using the custom data loader function
from pyspark.sql import SparkSession

# Create a SparkSession
spark = SparkSession.builder.appName("Supply Chain Quality Control Data Loader").getOrCreate()

from pyspark.sql import SparkSession

# Specify the file path to the dataset
file_path = "df_cleaned.csv"

# Create a SparkSession
spark = SparkSession.builder.appName("Supply Chain Quality Control Data Loader").getOrCreate()

# Load the CSV file into a DataFrame
df = spark.read.csv(file_path, header=True, inferSchema=True)

# Display the schema of the dataset
print("\n=== Data Schema ===")
df.printSchema()
=== Data Schema ===
root
 |-- Ordered Quantity: double (nullable = true)
 |-- Shipped Quantity: double (nullable = true)
 |-- Illustrative Price: double (nullable = true)
 |-- Average Days Late: double (nullable = true)
 |-- On Time (OTD): double (nullable = true)
 |-- In Full (IFD): double (nullable = true)
 |-- Delivery Progress: double (nullable = true)
 |-- Estimated Lead Time in Days: double (nullable = true)
 |-- Number of Shipments: double (nullable = true)
 |-- Order Cycle Time: double (nullable = true)

# Select the first 10 columns
first_10_columns = df.columns[:10]  # Adjusted to get the first 10 columns, not 20:30

# Select those columns from the DataFrame
selected_df = df.select(first_10_columns)

# Show the first 10 records of the selected features
print("\n=== First 10 Records of Relevant Features ===")
selected_df.show(10)
=== First 10 Records of Relevant Features ===
+----------------+----------------+------------------+-----------------+-------------+-------------+-----------------+---------------------------+-------------------+----------------+
|Ordered Quantity|Shipped Quantity|Illustrative Price|Average Days Late|On Time (OTD)|In Full (IFD)|Delivery Progress|Estimated Lead Time in Days|Number of Shipments|Order Cycle Time|
+----------------+----------------+------------------+-----------------+-------------+-------------+-----------------+---------------------------+-------------------+----------------+
|            15.0|            15.0|             25.75|             30.0|        100.0|        100.0|              2.0|         161.94305269017912|                1.0|            91.0|
|           210.0|           210.0|             137.0|              4.0|        100.0|        100.0|              2.0|                      140.0|                1.0|           501.0|
|            26.0|            26.0|             137.0|             18.0|        100.0|        100.0|              2.0|                      147.0|                1.0|           304.0|
|            12.0|            12.0|              64.4|              3.0|        100.0|        100.0|              2.0|                      105.0|                1.0|           194.0|
|            48.0|            48.0|             150.0|             -7.0|        100.0|        100.0|              2.0|         161.94305269017912|                1.0|           107.0|
|           306.0|           306.0|             260.0|             -6.0|        100.0|        100.0|              2.0|                      154.0|                1.0|           151.0|
|           150.0|           150.0|             260.0|              5.0|        100.0|        100.0|              2.0|                       70.0|                1.0|           153.0|
|            65.0|            65.0|             260.0|             -4.0|        100.0|        100.0|              2.0|                        0.0|                1.0|           197.0|
|           210.0|           210.0|             137.0|              4.0|        100.0|        100.0|              2.0|                      140.0|                1.0|           501.0|
|            27.0|            27.0|             515.7|              0.0|        100.0|        100.0|              2.0|         161.94305269017912|                1.0|            44.0|
+----------------+----------------+------------------+-----------------+-------------+-------------+-----------------+---------------------------+-------------------+----------------+
only showing top 10 rows

Correlation Matrix

pandas_df = selected_df.toPandas()

# Compute correlation matrix
correlation_matrix = pandas_df.corr()

# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title('Correlation Among Relevant Variables')
plt.show()
No description has been provided for this image
!pip install --upgrade tensorflow
import nest_asyncio
nest_asyncio.apply()
^C
Identify Suitable Algorithms
Given the dataset above and project objectives, the following algorithms and corresponding models are suitable:

Linear Regression Model

Random Forest Regressor

Gradient Boosting Regressor

Neural Network Evaluation Graphs

# import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.inspection import partial_dependence
from sklearn.inspection import PartialDependenceDisplay
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
import pandas as pd



class DataPreprocessor:
    def _init_(self, file_path):
        self.file_path = file_path
        self.data = None

    def load_data(self):
        # Load your data here
        self.data = pd.read_csv(self.file_path)

    def preprocess_data(self):
        # Preprocess your data here
        pass

    def get_processed_data(self):
        # Assume the last column is the target
        X = self.data.iloc[:, :-1]
        y = self.data.iloc[:, -1]
        return train_test_split(X, y, test_size=0.2, random_state=42)


def plot_residuals(y_true, y_pred, model_name):
    residuals = y_true - y_pred
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x=y_pred, y=residuals)
    plt.axhline(0, color='red', linestyle='--')
    plt.title(f'{model_name} - Residuals vs Predicted')
    plt.xlabel('Predicted Values')
    plt.ylabel('Residuals')
    plt.show()


def plot_actual_vs_predicted(y_true, y_pred, model_name):
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x=y_true, y=y_pred)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], color='red', linestyle='--')
    plt.title(f'{model_name} - Actual vs Predicted')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.show()

# run_neural_network:
def run_neural_network(data):
    X_train, X_test, y_train, y_test = data

    # Define the neural network model
    model = Sequential()
    model.add(Input(shape=(X_train.shape[1],)))  # Explicit input layer
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))

    model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])

    # Train the model and capture the training history
    history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, verbose=0)

    # Predict on the test set
    y_pred = model.predict(X_test).flatten()

    # Evaluate and display metrics
    print("Neural Network Results")
    print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"R^2 Score: {r2_score(y_test, y_pred):.2f}")

    # Export loss and accuracy curve data
    export_loss_and_accuracy_curves(history, "Neural_Network")

    # Export actual vs predicted and residuals vs predicted
    actual_vs_predicted_df = pd.DataFrame({
        'Actual': y_test,
        'Predicted': y_pred
    })
    residuals_vs_predicted_df = pd.DataFrame({
        'Residuals': y_test - y_pred,
        'Predicted': y_pred
    })

    # Combine all relevant data into a single DataFrame
    neural_network_results = pd.concat([
        actual_vs_predicted_df,
        residuals_vs_predicted_df,
        pd.DataFrame({'Epoch': range(1, len(history.history['loss']) + 1),
                      'Training Loss': history.history['loss'],
                      'Validation Loss': history.history['val_loss'],
                      'Training MAE': history.history['mae'],
                      'Validation MAE': history.history['val_mae']})
    ], axis=1)

    neural_network_results.to_csv("Neural_Network.csv", index=False)

    # Plot the loss curve
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title("Loss Curve - Neural Network")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.show(block=False)

    # Plot the accuracy curve (MAE)
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['mae'], label='Training MAE')
    plt.plot(history.history['val_mae'], label='Validation MAE')
    plt.title("Accuracy Curve (MAE) - Neural Network")
    plt.xlabel("Epochs")
    plt.ylabel("Mean Absolute Error")
    plt.legend()
    plt.show(block=False)

    # Plot residuals and actual vs predicted values
    plot_residuals(y_test, y_pred, "Neural Network")
    plot_actual_vs_predicted(y_test, y_pred, "Neural Network")

# run_gradient_boosting:
def run_gradient_boosting(data):
    X_train, X_test, y_train, y_test = data

    # Ensure X_train is a DataFrame if you want to use column names
    if isinstance(X_train, np.ndarray):
        # Provide column names manually if you're working with NumPy arrays
        feature_names = [f"Feature_{i}" for i in range(X_train.shape[1])]
    else:
        feature_names = X_train.columns

    model = GradientBoostingRegressor(random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print("Gradient Boosting Regressor Results")
    print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"R^2 Score: {r2_score(y_test, y_pred):.2f}")

    # Export actual vs predicted and residuals vs predicted
    actual_vs_predicted_df = pd.DataFrame({
        'Actual': y_test,
        'Predicted': y_pred
    })
    residuals_vs_predicted_df = pd.DataFrame({
        'Residuals': y_test - y_pred,
        'Predicted': y_pred
    })

    # Feature importances and Partial Dependence for plotting
    feature_importances = model.feature_importances_
    partial_dependence_df = pd.DataFrame({
        'Feature': feature_names,  # Use feature_names list instead of X_train.columns
        'Importance': feature_importances
    })

    # Combine all relevant data into a single DataFrame
    gradient_boosting_results = pd.concat([
        actual_vs_predicted_df,
        residuals_vs_predicted_df,
        partial_dependence_df
    ], axis=1)

    gradient_boosting_results.to_csv("Gradient_Boosting.csv", index=False)

    # Partial dependence plot using PartialDependenceDisplay
    fig, ax = plt.subplots(figsize=(8, 6))
    display = PartialDependenceDisplay.from_estimator(
        model, X_train, [0], ax=ax, grid_resolution=20
    )
    plt.title("Partial Dependence Plot")
    plt.show()  # Blocking plot

    # Residual and actual vs. predicted plots
    plot_residuals(y_test, y_pred, "Gradient Boosting Regressor")
    plot_actual_vs_predicted(y_test, y_pred, "Gradient Boosting Regressor")


# run_random_forest:
def run_random_forest(data):
    X_train, X_test, y_train, y_test = data
    model = RandomForestRegressor(random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print("Random Forest Regressor Results")
    print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"R^2 Score: {r2_score(y_test, y_pred):.2f}")

    # Export actual vs predicted and residuals vs predicted
    actual_vs_predicted_df = pd.DataFrame({
        'Actual': y_test,
        'Predicted': y_pred
    })
    residuals_vs_predicted_df = pd.DataFrame({
        'Residuals': y_test - y_pred,
        'Predicted': y_pred
    })

    # Feature importance data
    feature_importances = pd.DataFrame({
        'Feature': X_train.columns,
        'Importance': model.feature_importances_
    })

    # Combine all relevant data into a single DataFrame
    random_forest_results = pd.concat([
        actual_vs_predicted_df,
        residuals_vs_predicted_df,
        feature_importances
    ], axis=1)

    random_forest_results.to_csv("Random_Forest.csv", index=False)

    # Feature importance plot
    plt.figure(figsize=(10, 6))
    sns.barplot(x=model.feature_importances_, y=X_train.columns)
    plt.title("Feature Importance - Random Forest")
    plt.show()

    # Residuals and actual vs predicted plots
    plot_residuals(y_test, y_pred, "Random Forest Regressor")
    plot_actual_vs_predicted(y_test, y_pred, "Random Forest Regressor")

# run_linear_regression:
def run_linear_regression(data):
    X_train, X_test, y_train, y_test = data
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print("Linear Regression Results")
    print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"R^2 Score: {r2_score(y_test, y_pred):.2f}")

    # Export actual vs predicted and residuals vs predicted
    actual_vs_predicted_df = pd.DataFrame({
        'Actual': y_test,
        'Predicted': y_pred
    })
    residuals_vs_predicted_df = pd.DataFrame({
        'Residuals': y_test - y_pred,
        'Predicted': y_pred
    })

    # Combine all relevant data into a single DataFrame
    linear_regression_results = pd.concat([
        actual_vs_predicted_df,
        residuals_vs_predicted_df
    ], axis=1)

    linear_regression_results.to_csv("Linear_Regression.csv", index=False)

    # Residual and actual vs predicted plots
    plot_residuals(y_test, y_pred, "Linear Regression")
    plot_actual_vs_predicted(y_test, y_pred, "Linear Regression")




def compare_models(data):
    X_train, X_test, y_train, y_test = data

    results = {"Model": [], "R^2 Score": [], "Mean Absolute Error": []}

    # Linear Regression
    lr_model = LinearRegression()
    lr_model.fit(X_train, y_train)
    lr_pred = lr_model.predict(X_test)
    results["Model"].append("Linear Regression")
    results["R^2 Score"].append(r2_score(y_test, lr_pred))
    results["Mean Absolute Error"].append(mean_absolute_error(y_test, lr_pred))

    # Random Forest
    rf_model = RandomForestRegressor(random_state=42)
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict(X_test)
    results["Model"].append("Random Forest")
    results["R^2 Score"].append(r2_score(y_test, rf_pred))
    results["Mean Absolute Error"].append(mean_absolute_error(y_test, rf_pred))

    # Gradient Boosting
    gb_model = GradientBoostingRegressor(random_state=42)
    gb_model.fit(X_train, y_train)
    gb_pred = gb_model.predict(X_test)
    results["Model"].append("Gradient Boosting")
    results["R^2 Score"].append(r2_score(y_test, gb_pred))
    results["Mean Absolute Error"].append(mean_absolute_error(y_test, gb_pred))

    # Neural Network
    nn_model = Sequential()
    nn_model.add(Input(shape=(X_train.shape[1],)))
    nn_model.add(Dense(64, activation='relu'))
    nn_model.add(Dense(32, activation='relu'))
    nn_model.add(Dense(1))
    nn_model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])
    nn_model.fit(X_train, y_train, validation_split=0.2, epochs=50, verbose=0)
    nn_pred = nn_model.predict(X_test).flatten()
    results["Model"].append("Neural Network")
    results["R^2 Score"].append(r2_score(y_test, nn_pred))
    results["Mean Absolute Error"].append(mean_absolute_error(y_test, nn_pred))

    # Export results
    export_model_comparison(results)

    results_df = pd.DataFrame(results)
    print(results_df)



def main_menu():
    processed_data = DataPreprocessor(file_path="df_cleaned.csv")
    processed_data.load_data()
    processed_data.preprocess_data()

    while True:
        print("\n=== Model Selection ===")
        print("1. Linear Regression")
        print("2. Random Forest Regressor")
        print("3. Gradient Boosting Regressor")
        print("4. Neural Network")
        print("5. Compare All Models")
        print("6. Quit")

        choice = input("Choose a model (1-6): ")

        if choice == "1":
            run_linear_regression(processed_data.get_processed_data())
        elif choice == "2":
            run_random_forest(processed_data.get_processed_data())
        elif choice == "3":
            run_gradient_boosting(processed_data.get_processed_data())
        elif choice == "4":
            run_neural_network(processed_data.get_processed_data())
        elif choice == "5":
            compare_models(processed_data.get_processed_data())
        elif choice == "6":
            print("Exiting. Goodbye.")
            break
        else:
            print("Invalid choice. Please try again.")


if _name_ == "_main_":
    main_menu()
=== Model Selection ===
1. Linear Regression
2. Random Forest Regressor
3. Gradient Boosting Regressor
4. Neural Network
5. Compare All Models
6. Quit
Gradient Boosting Regressor Results
Mean Absolute Error: 78.57
R^2 Score: 0.35
No description has been provided for this image
No description has been provided for this image
No description has been provided for this image
=== Model Selection ===
1. Linear Regression
2. Random Forest Regressor
3. Gradient Boosting Regressor
4. Neural Network
5. Compare All Models
6. Quit
Linear Regression Results
Mean Absolute Error: 85.64
R^2 Score: 0.24
No description has been provided for this image
No description has been provided for this image
=== Model Selection ===
1. Linear Regression
2. Random Forest Regressor
3. Gradient Boosting Regressor
4. Neural Network
5. Compare All Models
6. Quit
Random Forest Regressor Results
Mean Absolute Error: 63.57
R^2 Score: 0.51
No description has been provided for this image
No description has been provided for this image
No description has been provided for this image
=== Model Selection ===
1. Linear Regression
2. Random Forest Regressor
3. Gradient Boosting Regressor
4. Neural Network
5. Compare All Models
6. Quit
264/264 ━━━━━━━━━━━━━━━━━━━━ 2s 8ms/step
Neural Network Results
Mean Absolute Error: 83.10
R^2 Score: 0.25
No description has been provided for this image
No description has been provided for this image
No description has been provided for this image
No description has been provided for this image
=== Model Selection ===
1. Linear Regression
2. Random Forest Regressor
3. Gradient Boosting Regressor
4. Neural Network
5. Compare All Models
6. Quit
264/264 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step
               Model  R^2 Score  Mean Absolute Error
0  Linear Regression   0.237479            85.635571
1      Random Forest   0.505070            63.573317
2  Gradient Boosting   0.347687            78.574732
3     Neural Network   0.254296            85.342428

=== Model Selection ===
1. Linear Regression
2. Random Forest Regressor
3. Gradient Boosting Regressor
4. Neural Network
5. Compare All Models
6. Quit
Exiting. Goodbye.
data = pd.read_csv("Neural_Network_loss_curve.csv")
reshaped_data = data.melt(id_vars="Epoch", 
                          var_name="Loss Metric Type", 
                          value_name="Loss-Value")
reshaped_data.to_csv("Reshaped_data-Neural_Network_loss_curve.csv", index=False)
data = pd.read_csv("Neural_Network_accuracy_curve.csv")
reshaped_data = data.melt(id_vars="Epoch", 
                          var_name="Accuracy Metric Type", 
                          value_name="Accuracy-Value")
reshaped_data.to_csv("Reshaped_data-Neural_Network_accuracy_curve.csv", index=False)
