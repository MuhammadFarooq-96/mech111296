{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1cf5c6-f611-4147-a7f5-d2df346aad61",
   "metadata": {},
   "source": [
    "# Model building, Evaluation & Evaluaton\n",
    "**Working on Cleaned dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4483adfc-10d6-4509-a068-55740f5fad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cc7b39-9044-4ed3-8e81-7e84bc836e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Schema ===\n",
      "root\n",
      " |-- Ordered Quantity: double (nullable = true)\n",
      " |-- Shipped Quantity: double (nullable = true)\n",
      " |-- Illustrative Price: double (nullable = true)\n",
      " |-- Average Days Late: double (nullable = true)\n",
      " |-- On Time (OTD): double (nullable = true)\n",
      " |-- In Full (IFD): double (nullable = true)\n",
      " |-- Delivery Progress: double (nullable = true)\n",
      " |-- Estimated Lead Time in Days: double (nullable = true)\n",
      " |-- Number of Shipments: double (nullable = true)\n",
      " |-- Order Cycle Time: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the cleaned dataset\n",
    "# Load the dataset using the custom data loader function\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Supply Chain Quality Control Data Loader\").getOrCreate()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Specify the file path to the dataset\n",
    "file_path = \"df_cleaned.csv\"\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Supply Chain Quality Control Data Loader\").getOrCreate()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display the schema of the dataset\n",
    "print(\"\\n=== Data Schema ===\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e60a35-faa9-4a49-ae1e-381b5cc061b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== First 10 Records of Relevant Features ===\n",
      "+----------------+----------------+------------------+-----------------+-------------+-------------+-----------------+---------------------------+-------------------+----------------+\n",
      "|Ordered Quantity|Shipped Quantity|Illustrative Price|Average Days Late|On Time (OTD)|In Full (IFD)|Delivery Progress|Estimated Lead Time in Days|Number of Shipments|Order Cycle Time|\n",
      "+----------------+----------------+------------------+-----------------+-------------+-------------+-----------------+---------------------------+-------------------+----------------+\n",
      "|            15.0|            15.0|             25.75|             30.0|        100.0|        100.0|              2.0|         161.94305269017912|                1.0|            91.0|\n",
      "|           210.0|           210.0|             137.0|              4.0|        100.0|        100.0|              2.0|                      140.0|                1.0|           501.0|\n",
      "|            26.0|            26.0|             137.0|             18.0|        100.0|        100.0|              2.0|                      147.0|                1.0|           304.0|\n",
      "|            12.0|            12.0|              64.4|              3.0|        100.0|        100.0|              2.0|                      105.0|                1.0|           194.0|\n",
      "|            48.0|            48.0|             150.0|             -7.0|        100.0|        100.0|              2.0|         161.94305269017912|                1.0|           107.0|\n",
      "|           306.0|           306.0|             260.0|             -6.0|        100.0|        100.0|              2.0|                      154.0|                1.0|           151.0|\n",
      "|           150.0|           150.0|             260.0|              5.0|        100.0|        100.0|              2.0|                       70.0|                1.0|           153.0|\n",
      "|            65.0|            65.0|             260.0|             -4.0|        100.0|        100.0|              2.0|                        0.0|                1.0|           197.0|\n",
      "|           210.0|           210.0|             137.0|              4.0|        100.0|        100.0|              2.0|                      140.0|                1.0|           501.0|\n",
      "|            27.0|            27.0|             515.7|              0.0|        100.0|        100.0|              2.0|         161.94305269017912|                1.0|            44.0|\n",
      "+----------------+----------------+------------------+-----------------+-------------+-------------+-----------------+---------------------------+-------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the first 10 columns\n",
    "first_10_columns = df.columns[:10]  # Adjusted to get the first 10 columns, not 20:30\n",
    "\n",
    "# Select those columns from the DataFrame\n",
    "selected_df = df.select(first_10_columns)\n",
    "\n",
    "# Show the first 10 records of the selected features\n",
    "print(\"\\n=== First 10 Records of Relevant Features ===\")\n",
    "selected_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247336f-08e6-4593-bc7b-b95f5fcbb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee41ea-c049-4e1b-8e2e-d1955860055a",
   "metadata": {},
   "source": [
    "# Identify Suitable Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507adbff-a163-4245-8070-c8b8766628ae",
   "metadata": {},
   "source": [
    "Given the dataset above and project objectives, the following algorithms and corresponding models are suitable:\n",
    "\n",
    "- **Regression Models** (Linear Regression, Neural Networks):\n",
    "\n",
    "Predict continuous variables such as Order Cycle Time.\n",
    "Metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE).\n",
    "\n",
    "- **Classification Models** (Logistic Regression, Neural Networks):\n",
    "\n",
    "Predict binary outcomes such as On Time Delivery (OTD) (1 for success, 0 for delay).\n",
    "Metrics: Accuracy, Precision, Recall, ROC-AUC.\n",
    "\n",
    "                                                        \n",
    "- **Ensemble Models** (e.g., Random Forest, Gradient Boosting with Keras Wrappers):\n",
    "\n",
    "Improve accuracy and handle complex data patterns for both regression and classification.\n",
    "\n",
    "                                                 \n",
    "- **Deep Learning Models** (e.g., Fully Connected Neural Networks):\n",
    "\n",
    "Capture intricate relationships and interactions between features for both regression and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8e9c7b-5414-45bb-87d0-ee9dc7af2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Selection ===\n",
      "1. Linear Regression\n",
      "2. Random Forest Regressor\n",
      "3. Gradient Boosting Regressor\n",
      "4. Neural Network\n",
      "5. Compare All Models\n",
      "6. Quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a model (1-6):  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omusi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\omusi\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\traceable_stack.py:129: RuntimeWarning: coroutine 'InteractiveShell.run_cell_async' was never awaited\n",
      "  return (t_obj.obj for t_obj in reversed(self._stack))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 186\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid choice. Please try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mmain_menu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 175\u001b[0m, in \u001b[0;36mmain_menu\u001b[1;34m()\u001b[0m\n\u001b[0;32m    173\u001b[0m     run_gradient_boosting(processed_data\u001b[38;5;241m.\u001b[39mget_processed_data())\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[43mrun_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_processed_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    177\u001b[0m     compare_models(processed_data\u001b[38;5;241m.\u001b[39mget_processed_data())\n",
      "Cell \u001b[1;32mIn[6], line 125\u001b[0m, in \u001b[0;36mrun_neural_network\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    119\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m    120\u001b[0m     Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_dim\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m    121\u001b[0m     Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    122\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    123\u001b[0m ])\n\u001b[0;32m    124\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 125\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeural Network Results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load your data here\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Preprocess your data here\n",
    "        pass\n",
    "\n",
    "    def get_processed_data(self):\n",
    "        # Assume the last column is the target\n",
    "        X = self.data.iloc[:, :-1]\n",
    "        y = self.data.iloc[:, -1]\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def plot_residuals(y_true, y_pred, model_name):\n",
    "    residuals = y_true - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title(f'{model_name} - Residuals vs Predicted')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_actual_vs_predicted(y_true, y_pred, model_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], color='red', linestyle='--')\n",
    "    plt.title(f'{model_name} - Actual vs Predicted')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_linear_regression(data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Linear Regression Results\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "    plot_residuals(y_test, y_pred, \"Linear Regression\")\n",
    "    plot_actual_vs_predicted(y_test, y_pred, \"Linear Regression\")\n",
    "\n",
    "\n",
    "def run_random_forest(data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Random Forest Regressor Results\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "    # Feature importance plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feature_importances = model.feature_importances_\n",
    "    sns.barplot(x=feature_importances, y=X_train.columns)\n",
    "    plt.title(\"Feature Importance - Random Forest\")\n",
    "    plt.show()\n",
    "\n",
    "    plot_residuals(y_test, y_pred, \"Random Forest Regressor\")\n",
    "    plot_actual_vs_predicted(y_test, y_pred, \"Random Forest Regressor\")\n",
    "\n",
    "\n",
    "def run_gradient_boosting(data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    model = GradientBoostingRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Gradient Boosting Regressor Results\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "    # Partial dependence plot using PartialDependenceDisplay\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    display = PartialDependenceDisplay.from_estimator(\n",
    "        model, X_train, [0], ax=ax, grid_resolution=20\n",
    "    )\n",
    "    plt.title(\"Partial Dependence Plot\")\n",
    "    plt.show()  # Blocking plot\n",
    "\n",
    "    # Residual and actual vs. predicted plots\n",
    "    plot_residuals(y_test, y_pred, \"Gradient Boosting Regressor\")\n",
    "    plot_actual_vs_predicted(y_test, y_pred, \"Gradient Boosting Regressor\")\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "def run_neural_network(data):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "\n",
    "    # Define the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))  # Explicit input layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Train the model and capture the training history\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, verbose=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "    # Evaluate and display metrics\n",
    "    print(\"Neural Network Results\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "    # Plot the loss curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"Loss Curve - Neural Network\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Plot the accuracy curve (MAE)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title(\"Accuracy Curve (MAE) - Neural Network\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.legend()\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Plot residuals and actual vs predicted values\n",
    "    plot_residuals(y_test, y_pred, \"Neural Network\")\n",
    "    plot_actual_vs_predicted(y_test, y_pred, \"Neural Network\")\n",
    "    \n",
    "\n",
    "def compare_models(data):\n",
    "    models = {\n",
    "        \"Linear Regression\": run_linear_regression(data),\n",
    "        \"Random Forest\": run_random_forest(data),\n",
    "        \"Gradient Boosting\": run_gradient_boosting(data),\n",
    "        \"Neural Network\": run_neural_network(data),\n",
    "    }\n",
    "\n",
    "    results = pd.DataFrame(models).T\n",
    "    best_model = results[\"R²\"].idxmax()\n",
    "\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    print(results)\n",
    "    print(f\"\\nBest Model: {best_model} (R²: {results.loc[best_model, 'R²']:.2f})\")\n",
    "\n",
    "\n",
    "def main_menu():\n",
    "    processed_data = DataPreprocessor(file_path=\"df_cleaned.csv\")\n",
    "    processed_data.load_data()\n",
    "    processed_data.preprocess_data()\n",
    "\n",
    "    while True:\n",
    "        print(\"\\n=== Model Selection ===\")\n",
    "        print(\"1. Linear Regression\")\n",
    "        print(\"2. Random Forest Regressor\")\n",
    "        print(\"3. Gradient Boosting Regressor\")\n",
    "        print(\"4. Neural Network\")\n",
    "        print(\"5. Compare All Models\")\n",
    "        print(\"6. Quit\")\n",
    "\n",
    "        choice = input(\"Choose a model (1-6): \")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            run_linear_regression(processed_data.get_processed_data())\n",
    "        elif choice == \"2\":\n",
    "            run_random_forest(processed_data.get_processed_data())\n",
    "        elif choice == \"3\":\n",
    "            run_gradient_boosting(processed_data.get_processed_data())\n",
    "        elif choice == \"4\":\n",
    "            run_neural_network(processed_data.get_processed_data())\n",
    "        elif choice == \"5\":\n",
    "            compare_models(processed_data.get_processed_data())\n",
    "        elif choice == \"6\":\n",
    "            print(\"Exiting. Goodbye.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0a8eb-effc-43ce-a491-08c9a6ea9216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
